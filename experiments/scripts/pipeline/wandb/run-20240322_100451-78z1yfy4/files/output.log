
==================================Global Round 0=================================
/opt/conda/envs/sfl/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(







































































































































































































































































































































Client 0 Epoch 0 Step (499, 499) Loss 1.723: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [15:23<00:00,  1.85s/it]
500 -1
Client 0 communication overhead: uplink:2.12 GB, downlink:2.12 GB
SERVER: AGGREGATION












































































































































































































































































































































Client 0 Epoch 0 Step (999, 999) Loss 1.583: 100%|████████████████████████████████████████████████████████████████████████████████████▊| 499/500 [11:04<00:01,  1.43s/it]
1000 -1
Client 0 communication overhead: uplink:4.27 GB, downlink:4.27 GB
SERVER: AGGREGATION
Global Round 0 communication overhead: uplink=4.27 GB, downlink=4.27 GB
SERVER: AGGREGATION

Client 0 Epoch 0 Step (999, 999) Loss 1.583: 100%|█████████████████████████████████████████████████████████████████████████████████████| 500/500 [15:24<00:00,  1.85s/it]