
==================================Global Round 0=================================
/opt/conda/envs/sfl/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(





































































































































































































































































































































































































































































Client 0 Epoch 0 Step (499, 499) Loss 1.723: 100%|█████████████████████████████████████████████████████████████████████████████████████| 500/500 [19:32<00:00,  2.35s/it]
500 -1
Client 0 communication overhead: uplink:2.12 GB, downlink:2.12 GB
SERVER: AGGREGATION

































































































































































































































































































































Client 0 Epoch 0 Step (999, 999) Loss 1.583: 100%|████████████████████████████████████████████████████████████████████████████████████▊| 499/500 [10:41<00:01,  1.29s/it]
1000 -1
Client 0 communication overhead: uplink:4.27 GB, downlink:4.27 GB
SERVER: AGGREGATION
Global Round 0 communication overhead: uplink=4.27 GB, downlink=4.27 GB
SERVER: AGGREGATION

Client 0 Epoch 0 Step (999, 999) Loss 1.583: 100%|█████████████████████████████████████████████████████████████████████████████████████| 500/500 [15:03<00:00,  1.81s/it]