
==================================Global Round 0=================================
/opt/conda/envs/sfl/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(












































Client 0 Epoch 0 Step (599, 599) Loss 0.435: 100%|█████████████████████████████████████████████████████████████████████████████| 600/600 [01:28<00:00,  6.76it/s]
600 1200
Client 0 communication overhead: uplink:3.14 GB, downlink:3.14 GB
SERVER: AGGREGATION










































Client 0 Epoch 0 Step (1189, 1189) Loss 0.057:  98%|█████████████████████████████████████████████████████████████████████████▊ | 590/600 [01:25<00:01,  8.27it/s]
1200 1200
Client 0 communication overhead: uplink:6.27 GB, downlink:6.27 GB
SERVER: AGGREGATION
Global Round 0 communication overhead: uplink=6.27 GB, downlink=6.27 GB
SERVER: AGGREGATION

Client 0 Epoch 0 Step (1199, 1199) Loss 1.148: 100%|███████████████████████████████████████████████████████████████████████████| 600/600 [01:26<00:00,  6.93it/s]