
==================================Global Round 0=================================
/opt/conda/envs/sfl/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(









































Client 0 Epoch 0 Step (596, 596) Loss 0.596:  99%|████████████████████████████████████████████████████████████████████████████▍| 596/600 [01:23<00:00,  7.87it/s]
600 1200
Client 0 communication overhead: uplink:3.14 GB, downlink:3.14 GB

Client 0 Epoch 0 Step (599, 599) Loss 0.435: 100%|█████████████████████████████████████████████████████████████████████████████| 600/600 [01:24<00:00,  7.10it/s]









































Client 0 Epoch 0 Step (1193, 1193) Loss 0.065:  99%|██████████████████████████████████████████████████████████████████████████▏| 593/600 [01:22<00:00,  9.42it/s]
1200 1200
Client 0 communication overhead: uplink:6.27 GB, downlink:6.27 GB
SERVER: AGGREGATION
Global Round 0 communication overhead: uplink=6.27 GB, downlink=6.27 GB
SERVER: AGGREGATION

Client 0 Epoch 0 Step (1199, 1199) Loss 1.148: 100%|███████████████████████████████████████████████████████████████████████████| 600/600 [01:23<00:00,  7.15it/s]