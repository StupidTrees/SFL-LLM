
==================================Global Round 0=================================
/opt/conda/envs/sfl/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                                            | 0/600 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
































Client 0 Epoch 0 Step (599, 599) Loss 2.904: 100%|█████████████████████████████████████████████████████████████████████████████████████| 600/600 [01:05<00:00,  9.13it/s]
600 1200
Client 0 communication overhead: uplink:1.02 GB, downlink:1.02 GB
SERVER: AGGREGATION






























Client 0 Epoch 0 Step (1187, 1187) Loss 3.855:  98%|█████████████████████████████████████████████████████████████████████████████████▏ | 587/600 [01:00<00:01,  9.09it/s]
1200 1200
Client 0 communication overhead: uplink:2.03 GB, downlink:2.03 GB
SERVER: AGGREGATION
Global Round 0 communication overhead: uplink=2.03 GB, downlink=2.03 GB
SERVER: AGGREGATION

Client 0 Epoch 0 Step (1199, 1199) Loss 2.826: 100%|███████████████████████████████████████████████████████████████████████████████████| 600/600 [01:02<00:00,  9.65it/s]