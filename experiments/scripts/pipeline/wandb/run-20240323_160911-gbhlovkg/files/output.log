
==================================Global Round 0=================================
/opt/conda/envs/sfl/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                                            | 0/600 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.































Client 0 Epoch 0 Step (589, 589) Loss 3.311:  98%|███████████████████████████████████████████████████████████████████████████████████▍ | 589/600 [01:03<00:01,  9.25it/s]
600 1200
Client 0 communication overhead: uplink:1.02 GB, downlink:1.02 GB

Client 0 Epoch 0 Step (599, 599) Loss 2.904: 100%|█████████████████████████████████████████████████████████████████████████████████████| 600/600 [01:04<00:00,  9.25it/s]






























Client 0 Epoch 0 Step (1195, 1195) Loss 2.363:  99%|██████████████████████████████████████████████████████████████████████████████████▎| 595/600 [01:01<00:00, 10.28it/s]
1200 1200
Client 0 communication overhead: uplink:2.03 GB, downlink:2.03 GB
SERVER: AGGREGATION
Global Round 0 communication overhead: uplink=2.03 GB, downlink=2.03 GB
SERVER: AGGREGATION

Client 0 Epoch 0 Step (1199, 1199) Loss 2.826: 100%|███████████████████████████████████████████████████████████████████████████████████| 600/600 [01:02<00:00,  9.64it/s]