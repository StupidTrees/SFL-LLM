
==================================Global Round 0=================================
/opt/conda/envs/sfl/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(































































































































































































































































































































































































































Client 0 Epoch 0 Step (499, 499) Loss 1.723: 100%|█████████████████████████████████████████████████████████████████████████████████████| 500/500 [22:35<00:00,  2.71s/it]
500 -1
Client 0 communication overhead: uplink:2.12 GB, downlink:2.12 GB
SERVER: AGGREGATION




































































































































































































































































































































































































































Client 0 Epoch 0 Step (999, 999) Loss 1.583: 100%|████████████████████████████████████████████████████████████████████████████████████▊| 499/500 [14:01<00:01,  1.89s/it]
1000 -1
Client 0 communication overhead: uplink:4.27 GB, downlink:4.27 GB
SERVER: AGGREGATION
Global Round 0 communication overhead: uplink=4.27 GB, downlink=4.27 GB
SERVER: AGGREGATION

Client 0 Epoch 0 Step (999, 999) Loss 1.583: 100%|█████████████████████████████████████████████████████████████████████████████████████| 500/500 [22:34<00:00,  2.71s/it]