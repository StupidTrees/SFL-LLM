
==================================Global Round 0=================================
/opt/conda/envs/sfl/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(







































Client 0 Epoch 0 Step (599, 599) Loss 1.993: 100%|█████████████████████████████████████████████████████████████████████████████| 600/600 [01:19<00:00,  7.58it/s]
600 1200
Client 0 communication overhead: uplink:599.30 MB, downlink:599.30 MB
SERVER: AGGREGATION




































Client 0 Epoch 0 Step (1196, 1196) Loss 1.968:  99%|██████████████████████████████████████████████████████████████████████████▌| 596/600 [01:14<00:00,  8.59it/s]
1200 1200
Client 0 communication overhead: uplink:1.16 GB, downlink:1.16 GB
SERVER: AGGREGATION
Global Round 0 communication overhead: uplink=1.16 GB, downlink=1.16 GB
SERVER: AGGREGATION

Client 0 Epoch 0 Step (1199, 1199) Loss 1.705: 100%|███████████████████████████████████████████████████████████████████████████| 600/600 [01:15<00:00,  7.98it/s]